{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the OpenDSM library\n",
    "\n",
    "This jupyter notebook is an interactive tutorial. It walks through loading data, utilizing OpenEEmeter models, and plotting results. You'll run all the code yourself. Cells can be executed with `<shift><enter>`. Feel free to make edits to the code in these cells and dig deeper.\n",
    "\n",
    "### Note on tutorial scope\n",
    "\n",
    "This tutorial assumes the reader has properly installed python and the OpenDSM package (`pip install opendsm`) and has a basic working knowledge of python syntax and usage.\n",
    "\n",
    "## Outline\n",
    "\n",
    "This tutorial is a walkthrough of how to use the OpenDSM package. We'll cover the following:\n",
    "\n",
    "- Background - why this library\n",
    "- Loading data\n",
    "- Fitting OpenEEmeter models\n",
    "- Prediction of fit models\n",
    "- Computing metered savings\n",
    "\n",
    "The tutorial is focused on demonstrating how to use the package to run the Hourly, Daily, and Billing models.\n",
    "\n",
    "## Background and Cautions\n",
    "\n",
    "[OpenDSM](https://lfenergy.org/projects/opendsm/) is an open-source library which can be used to calculate avoided energy consumption on an individual meter. It pulls weather data using `EEweather`, fits models on training (baseline) data using the `OpenEEmeter` module, predicts using those models on testing (reporting) data, and corrects models for population-level changes via `GRIDmeter`. This tutorial will focus on the OpenEEmeter portion of this sequence. OpenEEmeter is the successor of the [CalTRACK](http://www.caltrack.org/) methodology. Initially OpenEEmeter was the complete open source implementation of the CalTRACK methodology, but it has since evolved beyond the CalTRACK models.\n",
    "\n",
    "The `OpenEEmeter` module is built for flexibility and modularity. While this makes it easier to use the package, without following the documentation and the guidance provided, it is very possible to use the module in a way that does not comply with the approved methodology. For example, while the `OpenEEmeter` models set specific hard limits for the purpose of standardization and consistency, they can be configured to edit or entirely ignore those limits. The reason for this flexibility is to facilitate research, development, and testing of potential changes to the models. Usage of `OpenEEmeter` does not in itself guarantee compliance with the accepted methodology if nondefault configurations are used.\n",
    "\n",
    "Some new users have assumed that the OpenDSM package constitutes an entire application suitable for running metering analytics at scale. This is not necessarily the case. It is designed instead to be embedded within other applications or to be used in one-off analyses. OpenDSM leaves it up to the user to decide when to use or how to embed the provided tools within other applications. This limitation is an important consequence of the decision to make the models and tools as open and accessible as possible as not all users will have access to enterprise-level infrastructure.\n",
    "\n",
    "As you dive in, remember that this is a work in progress and that we welcome feedback and contributions. To contribute, please open an [issue](https://github.com/opendsm/opendsm/issues) or a [pull request](https://github.com/opendsm/opendsm/pulls) on github.\n",
    "\n",
    "### Jupyter housekeeping\n",
    "\n",
    "*Note: these Jupyter cell magics enable some useful special features but are unrelated to eemeter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# allow live package editing\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the OpenDSM library\n",
    "\n",
    "Once the OpenDSM has been installed, it can be imported as shown below.\n",
    "\n",
    "This tutorial requires OpenDSM version > 1.2.x. Verify the version you have installed.\n",
    "\n",
    "We will load eemeter and drmeter modules separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenDSM 1.2.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import opendsm as odsm\n",
    "from opendsm import (\n",
    "    eemeter as em,\n",
    "    drmeter as dm,\n",
    ")\n",
    "\n",
    "print(f\"OpenDSM {odsm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The essential inputs to OpenDSM library functions are the following:\n",
    "\n",
    "1. Meter baseline data named `observed`\n",
    "2. Meter reporting data `observed`\n",
    "3. Temperature data from a nearby weather station for both named `temperature`\n",
    "4. All data is expected to have a timezone-aware datetime index or column named `datetime`\n",
    "\n",
    "Users of the library are responsible for obtaining and formatting this data (to get weather data, see [eeweather](https://eeweather.openee.io/), which helps perform site to weather station matching and can pull and cache temperature data directly from public (US) data sources). Some samples come loaded with the library and we'll load these first to save you the trouble of loading in your own data.\n",
    "\n",
    "We utilize data classes to store meter data, perform transforms, and validate the data to ensure data compliance. The inputs into these data classes can either be [pandas](https://pandas.pydata.org/) `DataFrame` if initializing the classes directly or `Series` if initializing the classes using `.from_series`.\n",
    "\n",
    "The test data contained within the OpenDSM library is derived from [NREL ComStock](https://comstock.nrel.gov/) simulations.\n",
    "\n",
    "If working with your own data instead of these samples, please refer directly to the excellent pandas documentation for instructions for loading data (e.g., [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)).\n",
    "\n",
    "### Important notes about data:\n",
    "- *These models were developed and tested using Fahrenheit temperature. Please convert your temperatures accordingly*\n",
    "- *It is expected that all data is trimmed to its appropriate time period (baseline and reporting) and does not contain extraneous datetimes*\n",
    "- *If you run load_test_data it will download the necessary files from the OpenDSM repository. This can be up to 150 MB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in test data\n",
    "#     - This data contains 100 different meters\n",
    "\n",
    "df_baseline, df_reporting = odsm.test_data.load_test_data(\"monthly_treatment_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BILLING EXAMPLE\n",
    "\n",
    "Let's repeat this to show how the billing model works almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the only difference in how these are called are the specific data classes and model used. Everything else remains the same.\n",
    "\n",
    "- As with the Daily data, Billing data should have hourly temperature\n",
    "- Billing data is reversed from a customer perspective. From a customer perspective, you pay for the month you used energy and so the bill is for the month prior. To model this, the start date should have the usage for a given month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "\n",
    "id = df_baseline.index.get_level_values(0).unique()[n]\n",
    "\n",
    "df_baseline_n = df_baseline.loc[id]\n",
    "df_reporting_n = df_reporting.loc[id]\n",
    "\n",
    "billing_baseline_data = em.BillingBaselineData(df_baseline_n, is_electricity_data=True)\n",
    "billing_reporting_data = em.BillingReportingData(df_reporting_n, is_electricity_data=True)\n",
    "\n",
    "billing_model = em.BillingModel().fit(billing_baseline_data, ignore_disqualification=False)\n",
    "billing_model.predict(billing_baseline_data).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The billing model prediction function does have additional functionality built into it where it can aggregate from averaged daily data to `monthly` or `bimonthly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_model.predict(billing_baseline_data, aggregation=\"monthly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the plot function also has the ability to aggregate to `monthly` or `bimonthly`. \n",
    "\n",
    "This model is still at its core, a modified daily model though. This is why the model prediction is not straight for either of the aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billing_model.plot(billing_baseline_data)\n",
    "\n",
    "billing_model.plot(billing_baseline_data, aggregation=\"monthly\")\n",
    "\n",
    "billing_model.plot(billing_baseline_data, aggregation=\"bimonthly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOURLY Energy Efficiency Model\n",
    "\n",
    "Just like the daily and billing model, we follow the same calls but for new data classes and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline, df_reporting = odsm.test_data.load_test_data(\"hourly_treatment_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "\n",
    "id = df_baseline.index.get_level_values(0).unique()[n]\n",
    "\n",
    "df_baseline_n = df_baseline.loc[id]\n",
    "df_reporting_n = df_reporting.loc[id]\n",
    "\n",
    "hourly_baseline_data = em.HourlyBaselineData(df_baseline_n, is_electricity_data=True)\n",
    "hourly_reporting_data = em.HourlyReportingData(df_reporting_n[[\"temperature\"]], is_electricity_data=True)\n",
    "\n",
    "hourly_model = em.HourlyModel().fit(hourly_baseline_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_model.predict(hourly_baseline_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Demand Response Model\n",
    "\n",
    "Finally, we have a demand response model meant to be used for measuring short-term demand response events within `drmeter`, but it too follows the same API structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline, df_reporting = odsm.test_data.load_test_data(\"hourly_treatment_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/applied_data_science/opendsm/opendsm/eemeter/models/hourly_caltrack/data.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[df[\"observed\"] == 0, \"observed\"] = np.nan\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "\n",
    "id = df_baseline.index.get_level_values(0).unique()[n]\n",
    "\n",
    "df_baseline_n = df_baseline.loc[id]\n",
    "df_reporting_n = df_reporting.loc[id]\n",
    "\n",
    "hourly_baseline_data = dm.CaltrackDRBaselineData(df_baseline_n, is_electricity_data=True)\n",
    "hourly_reporting_data = dm.CaltrackDRReportingData(df_reporting_n[[\"temperature\"]], is_electricity_data=True)\n",
    "\n",
    "dr_model = dm.CaltrackDRModel().fit(hourly_baseline_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>observed</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_uncertainty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00-06:00</th>\n",
       "      <td>-5.08</td>\n",
       "      <td>30.336523</td>\n",
       "      <td>31.670276</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00-06:00</th>\n",
       "      <td>-5.98</td>\n",
       "      <td>37.355408</td>\n",
       "      <td>32.070312</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00-06:00</th>\n",
       "      <td>-7.06</td>\n",
       "      <td>39.376695</td>\n",
       "      <td>32.714753</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00-06:00</th>\n",
       "      <td>-7.06</td>\n",
       "      <td>39.911217</td>\n",
       "      <td>32.758016</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00-06:00</th>\n",
       "      <td>-7.06</td>\n",
       "      <td>39.406699</td>\n",
       "      <td>32.789302</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 19:00:00-06:00</th>\n",
       "      <td>33.98</td>\n",
       "      <td>15.388135</td>\n",
       "      <td>11.477984</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 20:00:00-06:00</th>\n",
       "      <td>33.98</td>\n",
       "      <td>15.261147</td>\n",
       "      <td>12.202178</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:00:00-06:00</th>\n",
       "      <td>33.98</td>\n",
       "      <td>13.970028</td>\n",
       "      <td>12.383450</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00-06:00</th>\n",
       "      <td>33.92</td>\n",
       "      <td>14.095850</td>\n",
       "      <td>12.120746</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00-06:00</th>\n",
       "      <td>33.98</td>\n",
       "      <td>3.519598</td>\n",
       "      <td>11.848909</td>\n",
       "      <td>29.326114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           temperature   observed  predicted  \\\n",
       "datetime                                                       \n",
       "2018-01-01 00:00:00-06:00        -5.08  30.336523  31.670276   \n",
       "2018-01-01 01:00:00-06:00        -5.98  37.355408  32.070312   \n",
       "2018-01-01 02:00:00-06:00        -7.06  39.376695  32.714753   \n",
       "2018-01-01 03:00:00-06:00        -7.06  39.911217  32.758016   \n",
       "2018-01-01 04:00:00-06:00        -7.06  39.406699  32.789302   \n",
       "...                                ...        ...        ...   \n",
       "2018-12-31 19:00:00-06:00        33.98  15.388135  11.477984   \n",
       "2018-12-31 20:00:00-06:00        33.98  15.261147  12.202178   \n",
       "2018-12-31 21:00:00-06:00        33.98  13.970028  12.383450   \n",
       "2018-12-31 22:00:00-06:00        33.92  14.095850  12.120746   \n",
       "2018-12-31 23:00:00-06:00        33.98   3.519598  11.848909   \n",
       "\n",
       "                           predicted_uncertainty  \n",
       "datetime                                          \n",
       "2018-01-01 00:00:00-06:00              29.326114  \n",
       "2018-01-01 01:00:00-06:00              29.326114  \n",
       "2018-01-01 02:00:00-06:00              29.326114  \n",
       "2018-01-01 03:00:00-06:00              29.326114  \n",
       "2018-01-01 04:00:00-06:00              29.326114  \n",
       "...                                          ...  \n",
       "2018-12-31 19:00:00-06:00              29.326114  \n",
       "2018-12-31 20:00:00-06:00              29.326114  \n",
       "2018-12-31 21:00:00-06:00              29.326114  \n",
       "2018-12-31 22:00:00-06:00              29.326114  \n",
       "2018-12-31 23:00:00-06:00              29.326114  \n",
       "\n",
       "[8760 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_model.predict(hourly_baseline_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to calculate savings or avoided energy use\n",
    "\n",
    "Savings calculation functions are not provided in `eemeter`, but to calculate basic savings is a summation of the subtraction of reporting year observed from baseline year prediction for 1 year.\n",
    "\n",
    "- Savings = sum(predicted_baseline - observed_reporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img_path = \"/app/applied_data_science/opendsm/website/src/images/eemeter/daily_billing/billing_model_balance_points.png\"\n",
    "img = Image.open(img_path).convert(\"RGBA\")\n",
    "\n",
    "# Create a white background image\n",
    "white_bg = Image.new(\"RGBA\", img.size, (255, 255, 255, 255))\n",
    "\n",
    "# Composite the original image onto the white background\n",
    "composited = Image.alpha_composite(white_bg, img)\n",
    "\n",
    "# Convert back to RGB (no alpha) and save, overwriting the original\n",
    "composited.convert(\"RGB\").save(img_path)\n",
    "\n",
    "print(f\"Image at {img_path} has been updated to have a white background.\")\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
